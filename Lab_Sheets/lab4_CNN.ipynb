{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a902ed",
   "metadata": {},
   "source": [
    "Lab sheet -04 (CNN lab session)\n",
    "\n",
    "22UG1-0285\n",
    "\n",
    "K.G.G.R Bandara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182eec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23571e5e",
   "metadata": {},
   "source": [
    "# ===================================\n",
    "# PART 1: CIFAR-10 PRACTICAL SESSION\n",
    "# ==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28171a4b",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8499bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec218ba0",
   "metadata": {},
   "source": [
    "Step -01: Load and pepare CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "073cf057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading CIFAR-10 Dataset ===\n",
      "Training data shape: (50000, 32, 32, 3)\n",
      "Test data shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset (60,000 images of 10 classes)\n",
    "print(\"=== Loading CIFAR-10 Dataset ===\")\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "print(\"Training data shape:\", train_images.shape)\n",
    "print(\"Test data shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5f70ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized sucessfully\n"
     ]
    }
   ],
   "source": [
    "#Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(\"Data normalized sucessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef63bb2",
   "metadata": {},
   "source": [
    "Step 2: Build base CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d739cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CNN model sucessfully\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    # Convolutional Base\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Building CNN model sucessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c70af5",
   "metadata": {},
   "source": [
    "Step 03: Model summary and layer details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fe269e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Summary ===\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 6, 6, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122570 (478.79 KB)\n",
      "Trainable params: 122570 (478.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Model Summary ===\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccca0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Layer details ===\n",
      "Layer 1: conv2d_24\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 30, 30, 32)\n",
      "  Parameters: 896\n",
      "--------------------------------------------------\n",
      "Layer 2: max_pooling2d_16\n",
      "  Type: MaxPooling2D\n",
      "  Output Shape: (None, 15, 15, 32)\n",
      "  Parameters: 0\n",
      "--------------------------------------------------\n",
      "Layer 3: conv2d_25\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 13, 13, 64)\n",
      "  Parameters: 18496\n",
      "--------------------------------------------------\n",
      "Layer 4: max_pooling2d_17\n",
      "  Type: MaxPooling2D\n",
      "  Output Shape: (None, 6, 6, 64)\n",
      "  Parameters: 0\n",
      "--------------------------------------------------\n",
      "Layer 5: conv2d_26\n",
      "  Type: Conv2D\n",
      "  Output Shape: (None, 4, 4, 64)\n",
      "  Parameters: 36928\n",
      "--------------------------------------------------\n",
      "Layer 6: flatten_8\n",
      "  Type: Flatten\n",
      "  Output Shape: (None, 1024)\n",
      "  Parameters: 0\n",
      "--------------------------------------------------\n",
      "Layer 7: dense_16\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 64)\n",
      "  Parameters: 65600\n",
      "--------------------------------------------------\n",
      "Layer 8: dense_17\n",
      "  Type: Dense\n",
      "  Output Shape: (None, 10)\n",
      "  Parameters: 650\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Layer details ===\")\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"Layer {i+1}: {layer.name}\")\n",
    "    print(f\"  Type: {layer.__class__.__name__}\")\n",
    "    print(f\"  Output Shape: {layer.output_shape}\")\n",
    "    print(f\"  Parameters: {layer.count_params()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad961008",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# PART 2: MNIST MINI PROJECT\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdaa97",
   "metadata": {},
   "source": [
    "Step 01: Load and prepare MINST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d113b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading MNIST Dataset ===\n",
      "MNIST training shape: (60000, 28, 28, 1)\n",
      "MNIST test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Loading MNIST Dataset ===\")\n",
    "\n",
    "#Load the dataset\n",
    "(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = datasets.mnist.load_data()\n",
    "\n",
    "# Reshape images to add channel dimension (since these are grayscale images) & normalize pixel values\n",
    "train_images_mnist = train_images_mnist.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images_mnist = test_images_mnist.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "#print Shapes\n",
    "print(f\"MNIST training shape: {train_images_mnist.shape}\")\n",
    "print(f\"MNIST test shape: {test_images_mnist.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4791760",
   "metadata": {},
   "source": [
    "Step 2: Build base MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2636dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Building base MNIST model successfully \n"
     ]
    }
   ],
   "source": [
    "# Build the base model CNN\n",
    "base_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "print(\"\\n Building base MNIST model successfully \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f02fd",
   "metadata": {},
   "source": [
    "Base Model Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "027b2cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training base model ===\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 72s 41ms/step - loss: 0.1676 - accuracy: 0.9471 - val_loss: 0.0440 - val_accuracy: 0.9878\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 65s 38ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0388 - val_accuracy: 0.9888\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 59s 35ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0355 - val_accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 53s 32ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0318 - val_accuracy: 0.9920\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 53s 32ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0315 - val_accuracy: 0.9913\n",
      "313/313 - 3s - loss: 0.0274 - accuracy: 0.9909 - 3s/epoch - 10ms/step\n",
      "\n",
      "Base Model Test Accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "base_model.compile(optimizer='adam',\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train base model\n",
    "print(\"\\n=== Training base model ===\")\n",
    "base_history = base_model.fit(train_images_mnist, train_labels_mnist, epochs=5,\n",
    "                             validation_split=0.1)\n",
    "\n",
    "# Evaluate base model\n",
    "base_test_loss, base_test_acc = base_model.evaluate(test_images_mnist, test_labels_mnist, verbose=2)\n",
    "print(f\"\\nBase Model Test Accuracy: {base_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b92b0a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4bc2c",
   "metadata": {},
   "source": [
    "Step 03: Build modified MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54ccd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Building modified MNIST model successfully \n"
     ]
    }
   ],
   "source": [
    "modified_model = models.Sequential([\n",
    "    # Modified first layer with larger kernel\n",
    "    layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5), # Added dropout layer\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "print(\"\\n Building modified MNIST model successfully \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f8756",
   "metadata": {},
   "source": [
    "Modified_model test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5471afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training modified model ===\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 57s 32ms/step - loss: 0.2673 - accuracy: 0.9173 - val_loss: 0.0674 - val_accuracy: 0.9790\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 61s 36ms/step - loss: 0.0890 - accuracy: 0.9747 - val_loss: 0.0374 - val_accuracy: 0.9892\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 56s 33ms/step - loss: 0.0671 - accuracy: 0.9812 - val_loss: 0.0372 - val_accuracy: 0.9888\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 59s 35ms/step - loss: 0.0499 - accuracy: 0.9867 - val_loss: 0.0384 - val_accuracy: 0.9897\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 64s 38ms/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.0315 - val_accuracy: 0.9922\n",
      "313/313 - 5s - loss: 0.0282 - accuracy: 0.9924 - 5s/epoch - 16ms/step\n",
      "\n",
      "Modified Model Test Accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "modified_model.compile(optimizer='adam',\n",
    "                       loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Train modified model\n",
    "print(\"\\n=== Training modified model ===\")\n",
    "modified_history = modified_model.fit(train_images_mnist, train_labels_mnist, epochs=5,\n",
    "                                    validation_split=0.1)\n",
    "\n",
    "# Evaluate modified model\n",
    "modified_test_loss, modified_test_acc = modified_model.evaluate(test_images_mnist, test_labels_mnist, verbose=2)\n",
    "print(f\"\\nModified Model Test Accuracy: {modified_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270b6fa",
   "metadata": {},
   "source": [
    "Step 04: Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92057d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison Results ===\n",
      "Metric                    Base Model      Modified Model \n",
      "------------------------------------------------------------\n",
      "Test Accuracy             0.9909           0.9924\n",
      "Final Training Accuracy   0.9934           0.9876\n",
      "Final Validation Accuracy 0.9913           0.9922\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Comparison Results ===\")\n",
    "\n",
    "print(f\"{'Metric':<25} {'Base Model':<15} {'Modified Model':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"{'Test Accuracy':<25} {base_test_acc:.4f}{'':<10} {modified_test_acc:.4f}\")\n",
    "print(f\"{'Final Training Accuracy':<25} {base_history.history['accuracy'][-1]:.4f}{'':<10} {modified_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"{'Final Validation Accuracy':<25} {base_history.history['val_accuracy'][-1]:.4f}{'':<10} {modified_history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d4852",
   "metadata": {},
   "source": [
    "Training speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a0dabf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training speed comparison ===\n",
      "Metric                         Base Model      Modified Model \n",
      "------------------------------------------------------------\n",
      "Total Training Time (5 epochs) 262.47s         234.62s\n",
      "Time per Epoch                 52.49s         46.92s\n"
     ]
    }
   ],
   "source": [
    "# Calculate and compare training times\n",
    "import time\n",
    "\n",
    "# Base model training time measurement\n",
    "start_time = time.time()\n",
    "base_history = base_model.fit(train_images_mnist, train_labels_mnist, \n",
    "                             epochs=5, validation_split=0.1, verbose=0)\n",
    "base_train_time = time.time() - start_time\n",
    "\n",
    "# Modified model training time measurement\n",
    "start_time = time.time()\n",
    "modified_history = modified_model.fit(train_images_mnist, train_labels_mnist, \n",
    "                                    epochs=5, validation_split=0.1, verbose=0)\n",
    "modified_train_time = time.time() - start_time\n",
    "\n",
    "# Time per epoch comparison\n",
    "base_time_per_epoch = base_train_time / 5\n",
    "modified_time_per_epoch = modified_train_time / 5\n",
    "\n",
    "print(\"\\n=== Training speed comparison ===\")\n",
    "print(f\"{'Metric':<30} {'Base Model':<15} {'Modified Model':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total Training Time (5 epochs)':<30} {base_train_time:.2f}s{'':<8} {modified_train_time:.2f}s\")\n",
    "print(f\"{'Time per Epoch':<30} {base_time_per_epoch:.2f}s{'':<8} {modified_time_per_epoch:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46764426",
   "metadata": {},
   "source": [
    "Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01be7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Size Comparison ===\n",
      "Parameter Type       Base Model      Modified Model  Difference     \n",
      "-----------------------------------------------------------------\n",
      "Trainable            93322           93834           +512\n",
      "Non-trainable        0               0               +0\n",
      "Total                93322           93834           +512\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    trainable = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable = sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
    "    return trainable, non_trainable\n",
    "\n",
    "base_trainable, base_non_trainable = count_parameters(base_model)\n",
    "modified_trainable, modified_non_trainable = count_parameters(modified_model)\n",
    "\n",
    "print(\"\\n=== Model Size Comparison ===\")\n",
    "\n",
    "print(f\"{'Parameter Type':<20} {'Base Model':<15} {'Modified Model':<15} {'Difference':<15}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Trainable':<20} {base_trainable:<15} {modified_trainable:<15} {modified_trainable-base_trainable:+}\")\n",
    "print(f\"{'Non-trainable':<20} {base_non_trainable:<15} {modified_non_trainable:<15} {modified_non_trainable-base_non_trainable:+}\")\n",
    "print(f\"{'Total':<20} {base_trainable+base_non_trainable:<15} {modified_trainable+modified_non_trainable:<15} {(modified_trainable+modified_non_trainable)-(base_trainable+base_non_trainable):+}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
